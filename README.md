# ğŸ“¦ Product Scraper - Server Specifications Extractor

Un systÃ¨me de scraping automatisÃ© avancÃ© pour extraire les spÃ©cifications techniques complÃ¨tes des serveurs de diffÃ©rentes marques avec intelligence artificielle intÃ©grÃ©e.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Selenium](https://img.shields.io/badge/Selenium-WebDriver-green.svg)](https://selenium.dev)
[![AI](https://img.shields.io/badge/AI-Gemini-orange.svg)](https://ai.google.dev)
[![License](https://img.shields.io/badge/License-MIT-red.svg)](LICENSE)

## ğŸ“‹ FonctionnalitÃ©s

### ğŸ¯ **Extraction Multi-Marques**
- **ğŸ”¥ XFusion** : Scraper enhanced avec filtrage chassis/nodes et extraction dÃ©taillÃ©e
- **ğŸ–¥ï¸ Dell** : Serveurs AI PowerEdge avec navigation multi-onglets
- **ğŸ¢ HP** : Serveurs SMB avec couverture multi-URL
- **ğŸ’» Lenovo** : Scraping complet avec gestion des popups et scroll automation
- **âš¡ ASUS** : Extraction avec pagination et spÃ©cifications dÃ©taillÃ©es

### ğŸ”§ **FonctionnalitÃ©s AvancÃ©es**
- âœ… **Extraction des spÃ©cifications dÃ©taillÃ©es** depuis les pages individuelles
- âœ… **Filtrage intelligent** des chassis/nodes (XFusion)
- âœ… **Gestion des popups et cookies**
- âœ… **Scroll automation** pour le contenu dynamique
- âœ… **Multi-tab navigation** pour les ressources
- âœ… **Extraction des datasheets et images**
- âœ… **Pagination automatique**
- âœ… **Gestion d'erreurs robuste**

### ğŸ¤– **Intelligence Artificielle**
- **Gemini AI Integration** : Nettoyage et structuration des donnÃ©es
- **Traitement automatique** des spÃ©cifications techniques
- **Optimisation de la qualitÃ©** des donnÃ©es extraites

## ğŸ—ï¸ Structure du Projet

```
product-scraper/
â”‚
â”œâ”€â”€ ğŸ“ serveurs/                    # Scrapers par marque
â”‚   â”œâ”€â”€ xfusion.py                 # XFusion (Enhanced avec filtrage)
â”‚   â”œâ”€â”€ dell.py                    # Dell PowerEdge AI Servers
â”‚   â”œâ”€â”€ hp.py                      # HP SMB Servers
â”‚   â”œâ”€â”€ lenovo.py                  # Lenovo avec automation avancÃ©e
â”‚   â””â”€â”€ asus.py                    # ASUS avec pagination
â”‚
â”œâ”€â”€ ğŸ“ ai_processing/              # Traitement IA
â”‚   â””â”€â”€ gemini_cleaning.py         # Nettoyage Gemini AI
â”‚
â”œâ”€â”€ ğŸ“ database/                   # Connexion base de donnÃ©es
â”‚   â””â”€â”€ mysql_connector.py         # Connecteur MySQL
â”‚
â”œâ”€â”€ ğŸ“ automation/                 # Automatisation
â”‚   â””â”€â”€ scheduler.py               # Planificateur de tÃ¢ches
â”‚
â”œâ”€â”€ ğŸ“ stockage/                   # Scrapers stockage
â”‚   â”œâ”€â”€ dell.py
â”‚   â””â”€â”€ lenovo.py
â”‚
â”œâ”€â”€ ğŸ“ imprimantes_scanners/       # Scrapers imprimantes
â”‚   â”œâ”€â”€ dell.py
â”‚   â””â”€â”€ hp.py
â”‚
â”œâ”€â”€ ğŸ“„ main.py                     # Script principal
â”œâ”€â”€ ğŸ“„ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ README.md                   # Documentation
â””â”€â”€ ğŸ“„ .gitignore                  # Fichiers Ã  ignorer
```

## ğŸš€ Installation

### 1. **Cloner le repository**
```bash
git clone https://github.com/wassim100/product-scraper.git
cd product-scraper
```

### 2. **CrÃ©er un environnement virtuel**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

### 3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

### 4. **TÃ©lÃ©charger ChromeDriver**
- TÃ©lÃ©charger [ChromeDriver](https://chromedriver.chromium.org/)
- Placer `chromedriver.exe` dans le rÃ©pertoire racine

## ğŸ® Utilisation

### **Scraping Individual par Marque**

```python
# XFusion Enhanced (avec filtrage chassis/nodes)
from serveurs.xfusion import XFusionServerScraperImproved

scraper = XFusionServerScraperImproved()
servers = scraper.scrape_all_categories()
scraper.save_to_json(servers, "xfusion_servers.json")
```

```python
# Dell AI Servers
python serveurs/dell.py
```

```python
# HP SMB Servers
python serveurs/hp.py
```

### **Script Principal (All-in-One)**
```bash
python main.py --brand all
```

### **Traitement IA avec Gemini**
```python
from ai_processing.gemini_cleaning import process_json_file

# Nettoyer et structurer les donnÃ©es
process_json_file("servers_raw.json", "servers_cleaned.json")
```

## ğŸ“Š DonnÃ©es Extraites

### **Format JSON Standard**
```json
{
  "brand": "XFusion",
  "category": "AI Servers",
  "name": "FusionServer G5500 V7",
  "link": "https://www.xfusion.com/...",
  "tech_specs": {
    "Form Factor": "4U AI server",
    "Processor": "2 x 4th/5th Gen IntelÂ® XeonÂ® Scalable",
    "Memory": "32 x DIMMs at up to 5600 MT/s",
    "GPU Card": "10 x dual-width GPU cards",
    "Network": "3 x OCP 3.0 NICs",
    "...": "..."
  },
  "scraped_at": "2025-07-22T10:43:36.808174",
  "datasheet_link": "https://www.xfusion.com/en/resource/...",
  "image_url": "https://www.xfusion.com/wp-content/uploads/..."
}
```

## ğŸ”§ Configuration

### **Variables d'environnement (.env)**
```bash
# API Keys
GEMINI_API_KEY=your_gemini_api_key_here

# Database (optionnel)
MYSQL_HOST=localhost
MYSQL_USER=your_username
MYSQL_PASSWORD=your_password
MYSQL_DATABASE=servers_db

# Scraping Settings
DELAY_BETWEEN_REQUESTS=2
MAX_RETRIES=3
HEADLESS_MODE=true
```

## ğŸ¯ FonctionnalitÃ©s SpÃ©ciales

### **XFusion Enhanced**
- **Filtrage automatique** des chassis et nodes
- **Extraction dÃ©taillÃ©e** depuis les pages individuelles
- **Multi-tab navigation** pour datasheets et images
- **5 catÃ©gories** : Rack, High-Density, AI, Rack-Scale, FusionPoD

### **Lenovo Advanced**
- **Popup handling** automatique
- **Infinite scroll** automation
- **Load More** button clicking
- **Detailed specs** extraction from product pages

### **Dell Multi-Tab**
- **Socket-based** navigation
- **AI Servers** specialization
- **Tab switching** automation

## ğŸ§ª Tests

### **Scripts de Test Disponibles**
```bash
# Test des spÃ©cifications dÃ©taillÃ©es XFusion
python test_detailed_specs.py

# Test du filtrage chassis/nodes
python test_filtered_scraper.py

# Test d'extraction de produit unique
python test_single_product.py
```

## ğŸ“ˆ Statistiques du Projet

- **5 marques** couvertes
- **245+ KB** de donnÃ©es serveurs
- **100%** spÃ©cifications dÃ©taillÃ©es (XFusion)
- **Filtrage intelligent** chassis/nodes
- **Multi-format** support (tableaux, cartes, listes)

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Python 3.8+**
- **Selenium WebDriver** : Automation web
- **Google Gemini AI** : Traitement intelligent des donnÃ©es
- **MySQL** : Stockage base de donnÃ©es (optionnel)
- **JSON** : Format de donnÃ©es principal
- **Chrome/Chromium** : Navigateur pour scraping

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commit les changements (`git commit -am 'Ajout nouvelle fonctionnalitÃ©'`)
4. Push vers la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. CrÃ©er une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ™ Remerciements

- **Selenium** pour l'automation web
- **Google Gemini AI** pour le traitement intelligent
- **ChromeDriver** pour l'exÃ©cution des navigateurs

## ğŸ“ Contact

- **Auteur** : Wassim
- **GitHub** : [wassim100](https://github.com/wassim100)
- **Repository** : [product-scraper](https://github.com/wassim100/product-scraper)

---

â­ **N'hÃ©sitez pas Ã  mettre une Ã©toile si ce projet vous aide !** â­
