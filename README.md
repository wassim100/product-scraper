# Product Scraper ‚Äì Serveurs, Stockage, Imprimantes & Scanners

Syst√®me de scraping automatis√© (multi‚Äëmarques) avec post‚Äëtraitement IA (Gemini) et insertion MySQL. Con√ßu pour √™tre rapide, modulable, et s√ªr (idempotent). 

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org) [![Selenium](https://img.shields.io/badge/Selenium-WebDriver-green.svg)](https://selenium.dev) [![AI](https://img.shields.io/badge/AI-Gemini-orange.svg)](https://ai.google.dev) [![License](https://img.shields.io/badge/License-MIT-red.svg)](LICENSE)

## üöÄ Principales fonctionnalit√©s
- Orchestrateur central (filtrage par cat√©gories/scripts) + variables d'environnement
- Extraction hybride: tuiles produits (DOM structur√©) + JSON‚ÄëLD + fallback PDP (enrichissement conditionnel)
- Normalisation IA (Gemini) avec batching, retries, contraintes de format JSON strict
- Upsert MySQL idempotent (cl√©s uniques `(brand, sku)` & `(brand, link_hash)`), d√©sactivation s√©lective (`ENABLE_DEACTIVATE_MISSING`)
- Flags de performance: `FAST_SCRAPE`, `HEADLESS_MODE`, `MAX_PRODUCTS`, `SKIP_PDP_ENRICH`
- Journalisation par script et artefacts JSON bruts / nettoy√©s
- CLI base de donn√©es (`database/db_cli.py`) pour test, listing, export, statistiques

## üß© P√©rim√®tre actuel
| Domaine        | Marques / Scripts |
|----------------|-------------------|
| Serveurs       | ASUS, Dell, HP (tile extractor + PDP fallback), Lenovo, XFusion |
| Stockage       | Dell, Lenovo |
| Imprimantes & Scanners | Epson (Printers + Scanner), HP |

## üèóÔ∏è Architecture (vue rapide)
```
ai_processing/        ‚Üí Nettoyage & politiques Gemini
automation/           ‚Üí Scheduler / orchestration
database/             ‚Üí Connexion, sch√©ma, CLI, migrations l√©g√®res
serveurs/, stockage/, imprimantes_scanners/  ‚Üí Scrapers sp√©cialis√©s
logs/                 ‚Üí Journaux d'ex√©cution
```

## ‚öôÔ∏è Installation
```powershell
git clone https://github.com/wassim100/product-scraper.git
cd product-scraper
python -m venv venv
venv\Scripts\Activate
pip install -r requirements.txt
```

Cr√©er un fichier `.env` (optionnel si valeurs par d√©faut) :
```env
GEMINI_API_KEY=VOTRE_CLE
MYSQL_HOST=localhost
MYSQL_USER=root
MYSQL_PASSWORD=
MYSQL_DATABASE=scraping_db
```

## üîë Variables d'environnement principales
| Variable | R√¥le |
|----------|------|
| HEADLESS_MODE | Ex√©cution Chrome sans interface |
| FAST_SCRAPE | Active optimisations (timeouts courts, images d√©sactiv√©es) |
| MAX_PRODUCTS | Limite par run (0 = illimit√©) |
| ENABLE_DB | Active insertion DB |
| ENABLE_AI_CLEANING | Active nettoyage Gemini post-scrape (scheduler) |
| ENABLE_DEACTIVATE_MISSING | D√©sactive en base les produits non revus dans le run |
| SKIP_PDP_ENRICH | Saute l'enrichissement PDP (HP) pour acc√©l√©rer |
| SCHEDULER_CATEGORIES | Filtre (serveurs,stockage,imprimantes_scanners) |
| SCHEDULER_SCRIPTS | Liste pr√©cise de scripts √† ex√©cuter |
| GEMINI_API_KEY | Cl√© API Gemini |

## üß™ Ex√©cution rapide (exemples)
Scraper 5 serveurs HP en mode rapide :
```powershell
$env:MAX_PRODUCTS=5; $env:FAST_SCRAPE="1"; $env:HEADLESS_MODE="1"; python .\serveurs\hp.py
```

Nettoyage IA manuel :
```powershell
python .\ai_processing\gemini_cleaning.py --in .\hp_servers_full.json --out .\hp_servers_full.cleaned.json --batch-size 2
```

Insertion DB (upsert) :
```powershell
$env:ENABLE_DEACTIVATE_MISSING="false"; python -c "from database.mysql_connector import save_to_database; print(save_to_database('hp_servers_full.cleaned.json','serveurs','HP'))"
```

Scheduler (cat√©gorie imprimantes & scanners uniquement) :
```powershell
$env:SCHEDULER_CATEGORIES="imprimantes_scanners"; python -m automation.scheduler
```

## üõ¢Ô∏è Sch√©ma & DB
- Cl√©s uniques : `(brand, sku)` et `(brand, link_hash)`
- Champs lifecycle: `is_active`, `scraped_at`, `last_seen`, `ai_processed` / `ai_processed_at`
- D√©sactivation conditionnelle contr√¥l√©e par `ENABLE_DEACTIVATE_MISSING`

## ü§ñ IA (Gemini)
Flux : JSON brut ‚Üí nettoyage (fusion specs / suppression bruit / normalisation cl√©s) ‚Üí `.cleaned.json` ‚Üí DB.
Gestion : lots (`--batch-size`), limite (`--limit`), robustesse (retry basique).

## üßπ Qualit√© / Robustesse
- Extraction HP refactoris√©e (tuiles ‚Üí hints consolid√©s ‚Üí JSON-LD ‚Üí fallback PDP cibl√©)
- `try/finally` syst√©matique pour fermeture navigateur
- Image-blocking en mode `FAST_SCRAPE`
- Normalisation specs (regex CPU / cores / RAM / stockage / PSU)

## üîç CLI Base de Donn√©es
Exemples :
```powershell
python -m database.db_cli test
python -m database.db_cli list --table serveurs --brand HP --limit 5
python -m database.db_cli brands --table serveurs
python -m database.db_cli export --table serveurs --brand HP --out hp_export.json
```

## üìÅ Fichiers ignor√©s (s√©curit√© & propret√©)
Le `.gitignore` exclut : logs, drivers, artefacts volumineux (`*_full.json`, fichiers `.cleaned.json`), environnements virtuels, secrets `.env`.

## üìù Licence
MIT ‚Äì voir `LICENSE`.

## ‚úÖ R√©sum√© des atouts
> Pipeline complet scrape ‚Üí enrichissement conditionnel ‚Üí nettoyage IA ‚Üí upsert MySQL, modulaire, performant et tra√ßable.

## ‚≠ê Contribution
PRs bienvenues : cr√©ez une branche, d√©veloppez, testez, ouvrez une Pull Request.

---
Si ce projet vous est utile, une √©toile GitHub est appr√©ci√©e.

---

_Documentation finale consolid√©e ‚Äì version stable._
### üéØ Extraction multi‚Äëmarques
- Serveurs: ASUS, Dell, HP, Lenovo, XFusion
- Stockage: Dell, Lenovo
- Imprimantes & Scanners: Epson (EpsonPrinters + EpsonScanner), HP

### üîß Fonctionnalit√©s avanc√©es
- Extraction des sp√©cifications d√©taill√©es depuis les pages produits
- Pagination robuste + gestion des popups/cookies
- Nettoyage IA automatique (Gemini) apr√®s chaque scraping
- Insertion MySQL avec cl√©s uniques, suivi lifecycle et d√©sactivation des produits non revus
- Orchestrateur unique avec logs par script, timeouts et filtres par cat√©gorie/script

### ü§ñ Intelligence Artificielle
- Gemini 1.5: nettoyage/structuration des `tech_specs`
- Fichiers `.cleaned.json` g√©n√©r√©s puis ins√©r√©s en base (pr√©f√©r√©s aux `.json` bruts)

## üèóÔ∏è Structure du projet

```
product-scraper/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ serveurs/                    # Scrapers serveurs (asus/dell/hp/lenovo/xfusion)
‚îÇ   ‚îú‚îÄ‚îÄ asus.py
‚îÇ   ‚îú‚îÄ‚îÄ dell.py
‚îÇ   ‚îú‚îÄ‚îÄ hp.py
‚îÇ   ‚îú‚îÄ‚îÄ lenovo.py
‚îÇ   ‚îî‚îÄ‚îÄ xfusion.py
‚îÇ
‚îú‚îÄ‚îÄ üìÅ ai_processing/              # Traitement IA
‚îÇ   ‚îî‚îÄ‚îÄ gemini_cleaning.py         # Nettoyage Gemini AI
‚îÇ
‚îú‚îÄ‚îÄ üìÅ database/                   # Base de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ config.py                  # Param√®tres MySQL
‚îÇ   ‚îú‚îÄ‚îÄ mysql_connector.py         # Connecteur + cr√©ation/migrations simples
‚îÇ   ‚îî‚îÄ‚îÄ test_mysql.py              # Test de connexion
‚îÇ
‚îú‚îÄ‚îÄ üìÅ automation/                 # Automatisation
‚îÇ   ‚îî‚îÄ‚îÄ scheduler.py               # Planificateur de t√¢ches
‚îÇ
‚îú‚îÄ‚îÄ üìÅ stockage/                   # Scrapers stockage
‚îÇ   ‚îú‚îÄ‚îÄ dell.py
‚îÇ   ‚îî‚îÄ‚îÄ lenovo.py
‚îÇ
‚îú‚îÄ‚îÄ üìÅ imprimantes_scanners/       # Imprimantes & scanners
‚îÇ   ‚îú‚îÄ‚îÄ EpsonPrinters.py           # Epson (imprimantes)
‚îÇ   ‚îú‚îÄ‚îÄ EpsonScanner.py            # Epson (scanners)
‚îÇ   ‚îî‚îÄ‚îÄ hp.py                      # HP
‚îÇ
‚îú‚îÄ‚îÄ üìÑ main.py                     # Script principal
‚îú‚îÄ‚îÄ üìÑ requirements.txt            # D√©pendances Python
‚îú‚îÄ‚îÄ üìÑ README.md                   # Documentation
‚îî‚îÄ‚îÄ üìÑ .gitignore                  # Fichiers √† ignorer
```

## üöÄ Installation (Windows)

### 1. **Cloner le repository**
```powershell
git clone https://github.com/wassim100/product-scraper.git
cd product-scraper
```

### 2. **Cr√©er un environnement virtuel**
```powershell
python -m venv venv
venv\Scripts\Activate
```

### 3. **Installer les d√©pendances**
```powershell
pip install -r requirements.txt
```

### 4. ChromeDriver
- Optionnel: placez `chromedriver.exe` √† la racine. Sinon Selenium Manager r√©soudra automatiquement.
>>>>>>> 2b8329a (feat(epson): add EpsonPrinters and EpsonScanner scrapers; orchestrator DB flow; brand-scoped deactivation flag; README overhaul)

## Troubleshooting

<<<<<<< HEAD
- Script names must match scheduler entries (EpsonPrinters.py, EpsonScanner.py)
- For partial tests: set MAX_PRODUCTS>0 and ENABLE_DEACTIVATE_MISSING=false
- Git: ensure local main tracks origin/main before pushing

## License

MIT
=======
### Orchestrateur (recommand√©)
Ex√©cuter tous les scrapers via le scheduler, avec filtres optionnels:

```powershell
# Ex√©cution manuelle unique
$env:HEADLESS_MODE="true"; $env:ENABLE_DB="true"; $env:ENABLE_AI_CLEANING="true"; `
$env:SCHEDULER_CATEGORIES="imprimantes_scanners"; `
$env:SCHEDULER_SCRIPTS="imprimantes_scanners/EpsonPrinters.py,imprimantes_scanners/EpsonScanner.py"; `
python .\main.py --mode schedule --manual-run
```

Flags utiles:
- HEADLESS_MODE=true|false
- ENABLE_DB=true|false (insertion DB par le scheduler)
- ENABLE_AI_CLEANING=true|false (nettoyage Gemini post‚Äëscrape)
- ENABLE_DEACTIVATE_MISSING=true|false (d√©sactivation des produits non revus)
- MAX_PRODUCTS=10 (run r√©duit de test)
- SCHEDULER_CATEGORIES=serveurs,stockage,imprimantes_scanners
- SCHEDULER_SCRIPTS=chemins,relatifs,aux,scripts

Astuce tests: pour √©viter de d√©sactiver des produits lors d‚Äôun run r√©duit (MAX_PRODUCTS>0), d√©finissez `ENABLE_DEACTIVATE_MISSING=false`.

### Ex√©cution directe d‚Äôun scraper (d√©veloppement)
```powershell
python .\imprimantes_scanners\EpsonPrinters.py
python .\imprimantes_scanners\EpsonScanner.py
```

### Traitement IA (manuel)
```powershell
python .\ai_processing\gemini_cleaning.py --in path\to\raw.json --out path\to\cleaned.json
```

## üì¶ Donn√©es extraites

### **Format JSON Standard**
```json
{
  "brand": "XFusion",
  "category": "AI Servers",
  "name": "FusionServer G5500 V7",
  "link": "https://www.xfusion.com/...",
  "tech_specs": {
    "Form Factor": "4U AI server",
    "Processor": "2 x 4th/5th Gen Intel Xeon Scalable",
    "Memory": "32 x DIMMs up to 5600 MT/s"
  },
  "scraped_at": "2025-07-22T10:43:36.808174",
  "datasheet_link": "https://www.xfusion.com/en/resource/...",
  "image_url": "https://www.xfusion.com/wp-content/uploads/..."
}
```

## üîß Configuration

### **Variables d'environnement (.env)**
```env
# API
GEMINI_API_KEY=your_gemini_api_key_here

# MySQL (optionnel si valeurs par d√©faut)
MYSQL_HOST=localhost
MYSQL_USER=root
MYSQL_PASSWORD=
MYSQL_DATABASE=scraping_db

# Scraping / Orchestrateur
HEADLESS_MODE=true
ENABLE_DB=true
ENABLE_AI_CLEANING=true
ENABLE_DEACTIVATE_MISSING=true
MAX_PRODUCTS=0
SCHEDULER_CATEGORIES=
SCHEDULER_SCRIPTS=
```

## üéØ D√©tails notables
- Cl√©s uniques DB: (brand, sku) et (brand, link_hash) pour d√©duplication fiable
- Champs lifecycle: is_active, last_seen + audit IA (ai_processed, ai_processed_at)
- Le scheduler force RUNNING_UNDER_SCHEDULER=1 pour √©viter les doubles insertions c√¥t√© scrapers

## üß™ Tests & validation
- Validez par runs r√©duits: `MAX_PRODUCTS=1` + `ENABLE_DEACTIVATE_MISSING=false`
- Consultez les logs par script dans `./logs/` et le rapport JSON d‚Äôex√©cution du scheduler

## üìà Bonnes pratiques
- Pr√©f√©rez les `.cleaned.json` pour l‚Äôinsertion DB
- √âvitez les runs r√©duits avec d√©sactivation active
- Placez le dossier sur un chemin court si OneDrive verrouille des fichiers

## üõ†Ô∏è Technologies utilis√©es

- **Python 3.8+**
- **Selenium WebDriver** : Automation web
- **Google Gemini AI** : Nettoyage structur√© des sp√©cifications
- **MySQL** : Stockage base de donn√©es (optionnel)
- **JSON** : Format de donn√©es principal
- **Chrome/Chromium** : Navigateur pour scraping

## ü§ù Contribution

1. Fork le projet
2. Cr√©er une branche feature (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commit les changements (`git commit -am 'Ajout nouvelle fonctionnalit√©'`)
4. Push vers la branche (`git push origin feature/nouvelle-fonctionnalite`)
5. Cr√©er une Pull Request

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

## üôè Remerciements

- **Selenium** pour l'automation web
- **Google Gemini AI** pour le traitement intelligent
- **ChromeDriver** pour l'ex√©cution des navigateurs

## üìû Contact

- **Auteur** : Wassim
- **GitHub** : [wassim100](https://github.com/wassim100)
- **Repository** : [product-scraper](https://github.com/wassim100/product-scraper)

---

‚≠ê **N'h√©sitez pas √† mettre une √©toile si ce projet vous aide !** ‚≠ê
>>>>>>> 2b8329a (feat(epson): add EpsonPrinters and EpsonScanner scrapers; orchestrator DB flow; brand-scoped deactivation flag; README overhaul)
