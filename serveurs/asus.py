from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from datetime import datetime
import json
import os
import time
import re
import sys

# Ajouter le chemin du module database
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from database.mysql_connector import save_to_database
ENABLE_DB = os.getenv("ENABLE_DB", "false").lower() == "true"

# ‚úÖ Param√®tres
CHROMEDRIVER_PATH = os.path.join(os.getcwd(), "chromedriver.exe")
URL = "https://servers.asus.com/products/Servers"
BASE = "https://servers.asus.com"
OUTPUT_JSON = "asus_servers_full.json"

# Configuration pour tests rapides
MAX_PAGES_TO_SCRAPE = 2  # ‚ö° SEULEMENT 2 PAGES pour test rapide
DELAY_BETWEEN_PRODUCTS = 1  # 1 seconde entre produits
DELAY_BETWEEN_PAGES = 2     # 2 secondes entre pages

# Configuration pour tests rapides
MAX_PAGES_TO_SCRAPE = 2  # ‚ö° SEULEMENT 2 PAGES pour test rapide
DELAY_BETWEEN_PRODUCTS = 1  # 1 seconde entre produits
DELAY_BETWEEN_PAGES = 2     # 2 secondes entre pages

# ‚úÖ Config navigateur avec options am√©lior√©es pour √©viter la d√©tection
options = webdriver.ChromeOptions()
options.add_argument("--start-maximized")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option('useAutomationExtension', False)
options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
options.add_argument("--disable-logging")
options.add_argument("--disable-gpu-sandbox")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
service = Service(CHROMEDRIVER_PATH)
driver = webdriver.Chrome(service=service, options=options)
driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

# D√©lais plus longs pour √©viter la d√©tection
wait = WebDriverWait(driver, 30)
driver.implicitly_wait(10)

# ‚úÖ Fonction pour extraire les sp√©cifications techniques d'un produit
def extract_product_specs(driver, wait, product_link):
    """Extrait les sp√©cifications techniques d'un produit"""
    try:
        driver.get(product_link)
        
        # Attendre le chargement de la page
        wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
        time.sleep(3)
        
        specs_dict = {}
        
        # M√©thode 1 : Recherche dans les tableaux de sp√©cifications
        try:
            spec_sections = driver.find_elements(By.CSS_SELECTOR, ".specifications, .spec-table, .tech-specs, table")
            for section in spec_sections:
                rows = section.find_elements(By.TAG_NAME, "tr")
                for row in rows:
                    cols = row.find_elements(By.TAG_NAME, "td")
                    if len(cols) >= 2:
                        key = cols[0].text.strip()
                        value = cols[1].text.strip()
                        if key and value:
                            specs_dict[key] = value
        except:
            pass
        
        # M√©thode 2 : Recherche dans les divs avec classes sp√©cifiques
        try:
            spec_divs = driver.find_elements(By.CSS_SELECTOR, ".spec-item, .specification-item, .feature-item")
            for div in spec_divs:
                try:
                    label = div.find_element(By.CSS_SELECTOR, ".label, .spec-label, .title, h4, strong").text.strip()
                    value = div.find_element(By.CSS_SELECTOR, ".value, .spec-value, .description, p, span").text.strip()
                    if label and value:
                        specs_dict[label] = value
                except:
                    continue
        except:
            pass
        
        # M√©thode 3 : Recherche g√©n√©rale de texte structur√©
        try:
            page_text = driver.find_element(By.TAG_NAME, "body").text
            # Recherche de patterns comme "Processeur: Intel Xeon" 
            patterns = [
                r'([^:\n]+):\s*([^\n]+)',
                r'([^-\n]+)-\s*([^\n]+)',
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, page_text, re.MULTILINE)
                for match in matches:
                    key, value = match[0].strip(), match[1].strip()
                    if (len(key) < 50 and len(value) < 200 and 
                        not any(x in key.lower() for x in ['http', 'www', 'click', 'more']) and
                        any(x in key.lower() for x in ['processor', 'memory', 'storage', 'network', 'power', 'dimension'])):
                        specs_dict[key] = value
        except:
            pass
        
        # Recherche du lien datasheet
        datasheet_link = None
        try:
            pdf_links = driver.find_elements(By.XPATH, "//a[contains(@href,'.pdf') or contains(text(),'datasheet') or contains(text(),'specification')]")
            if pdf_links:
                datasheet_link = pdf_links[0].get_attribute("href")
        except:
            pass
        
        # Recherche de l'image principale
        image_url = ""
        try:
            # Plusieurs s√©lecteurs possibles pour l'image
            image_selectors = [
                ".product-image img",
                ".main-image img", 
                ".hero-image img",
                "img[src*='product']",
                ".gallery img"
            ]
            for selector in image_selectors:
                try:
                    img_element = driver.find_element(By.CSS_SELECTOR, selector)
                    image_url = img_element.get_attribute("src")
                    if image_url:
                        break
                except:
                    continue
        except:
            pass
        
        return specs_dict, datasheet_link, image_url
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'extraction des specs: {e}")
        return {}, None, ""

# ‚úÖ Fonction pour extraire tous les produits avec pagination
def extract_all_products(driver, wait, base_url):
    """Extrait tous les produits en g√©rant la pagination"""
    all_products = []
    current_page = 1
    max_pages = MAX_PAGES_TO_SCRAPE  # Utiliser la config
    
    print(f"üîç Extraction avec limite de {max_pages} pages (modifiez MAX_PAGES_TO_SCRAPE pour plus)")
    
    # Aller √† la premi√®re page
    driver.get(base_url)
    time.sleep(3)
    
    while current_page <= max_pages:
        print(f"üìÑ Scraping page {current_page}/{max_pages}...")
        
        try:
            # Attendre le chargement des produits
            wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
            time.sleep(2)
            
            # Essayer de d√©tecter les produits
            product_items = driver.find_elements(By.CLASS_NAME, "product_box_item")
            
            # Si pas de produits avec ce s√©lecteur, essayer d'autres
            if not product_items:
                # Autres s√©lecteurs possibles pour ASUS
                alternative_selectors = [
                    ".product-item",
                    ".server-item", 
                    ".product-card",
                    "[data-testid='product']",
                    ".product",
                    ".product-box",
                    ".item"
                ]
                
                for selector in alternative_selectors:
                    product_items = driver.find_elements(By.CSS_SELECTOR, selector)
                    if product_items:
                        print(f"‚úÖ Produits trouv√©s avec s√©lecteur: {selector}")
                        break
            
            if not product_items:
                print(f"‚ùå Aucun produit trouv√© sur la page {current_page}")
                break
            
            print(f"üîç {len(product_items)} produits trouv√©s sur la page {current_page}")
            
            # Traiter les produits de cette page
            page_products = extract_products_from_page(driver, wait, product_items, current_page)
            all_products.extend(page_products)
            
            print(f"‚úÖ Page {current_page} termin√©e - Total produits: {len(all_products)}")
            
            # Ne pas chercher la page suivante si on a atteint la limite
            if current_page >= max_pages:
                print(f"üõë Limite de pages atteinte ({max_pages})")
                break
            
            # V√©rifier s'il y a une page suivante
            has_next_page = check_next_page(driver)
            if not has_next_page:
                print(f"‚úÖ Derni√®re page atteinte (page {current_page})")
                break
            
            # Pause entre les pages
            print(f"‚è≥ Pause de {DELAY_BETWEEN_PAGES}s entre les pages...")
            time.sleep(DELAY_BETWEEN_PAGES)
            
            # Naviguer vers la page suivante
            if not navigate_to_next_page(driver):
                print(f"‚ùå Impossible de naviguer vers la page suivante")
                break
                
            current_page += 1
            
        except Exception as e:
            print(f"‚ùå Erreur sur la page {current_page}: {e}")
            break
    
    print(f"üéØ Extraction termin√©e - {len(all_products)} produits au total")
    return all_products

def check_next_page(driver):
    """V√©rifie s'il y a une page suivante"""
    try:
        # M√©thode 1 : Chercher le bouton "suivant" ou num√©ro de page suivant
        next_selectors = [
            ".pagination .next:not(.disabled)",
            ".pagination a[aria-label='Next']:not(.disabled)",
            ".page-next:not(.disabled)",
            ".pagination-next:not(.disabled)",
            "button[title='Next']:not(.disabled)",
            ".fa-chevron-right:not(.disabled)",
            ".arrow-right:not(.disabled)"
        ]
        
        for selector in next_selectors:
            next_elements = driver.find_elements(By.CSS_SELECTOR, selector)
            if next_elements and next_elements[0].is_enabled():
                print(f"‚úÖ Page suivante d√©tect√©e avec s√©lecteur: {selector}")
                return True
        
        # M√©thode 2 : V√©rifier les num√©ros de page
        page_links = driver.find_elements(By.CSS_SELECTOR, ".pagination a, .page-number")
        current_page_elements = driver.find_elements(By.CSS_SELECTOR, ".pagination .active, .pagination .current, .current-page")
        
        if page_links and current_page_elements:
            # Extraire le num√©ro de page actuel
            try:
                current_page_text = current_page_elements[0].text.strip()
                current_page_num = int(current_page_text)
                
                # Chercher s'il y a une page suivante dans les liens
                for link in page_links:
                    link_text = link.text.strip()
                    if link_text.isdigit() and int(link_text) > current_page_num:
                        print(f"‚úÖ Page suivante trouv√©e: {link_text}")
                        return True
            except ValueError:
                pass
        
        # M√©thode 3 : M√©thode g√©n√©rale - chercher des √©l√©ments de pagination
        pagination_container = driver.find_elements(By.CSS_SELECTOR, ".pagination, .pager, .page-navigation")
        if pagination_container:
            # Chercher tous les liens dans la pagination
            all_links = pagination_container[0].find_elements(By.TAG_NAME, "a")
            clickable_links = [link for link in all_links if link.is_enabled() and link.text.strip()]
            
            if len(clickable_links) > 1:
                print(f"‚úÖ {len(clickable_links)} liens de pagination trouv√©s")
                return True
        
        print("‚ùå Aucune page suivante d√©tect√©e")
        return False
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de la v√©rification de pagination: {e}")
        return False

def navigate_to_next_page(driver):
    """Navigue vers la page suivante"""
    try:
        # Essayer de cliquer sur le bouton suivant
        next_selectors = [
            ".pagination .next:not(.disabled)",
            ".pagination a[aria-label='Next']:not(.disabled)", 
            ".page-next:not(.disabled)"
        ]
        
        for selector in next_selectors:
            next_buttons = driver.find_elements(By.CSS_SELECTOR, selector)
            if next_buttons and next_buttons[0].is_enabled():
                driver.execute_script("arguments[0].click();", next_buttons[0])
                time.sleep(3)
                return True
        
        # Si pas de bouton "suivant", essayer de trouver le num√©ro de page suivant
        current_page_elements = driver.find_elements(By.CSS_SELECTOR, ".pagination .active, .pagination .current")
        if current_page_elements:
            current_page_text = current_page_elements[0].text.strip()
            if current_page_text.isdigit():
                next_page_num = int(current_page_text) + 1
                next_page_link = driver.find_elements(By.XPATH, f"//a[text()='{next_page_num}']")
                if next_page_link:
                    driver.execute_script("arguments[0].click();", next_page_link[0])
                    time.sleep(3)
                    return True
        
        return False
        
    except Exception as e:
        print(f"‚ùå Erreur navigation page suivante: {e}")
        return False

def extract_products_from_page(driver, wait, product_items, page_num):
    """Extrait les produits d'une page donn√©e"""
    page_products = []
    
    for index, item in enumerate(product_items):
        try:
            # Extraction du nom
            name_element = item.find_element(By.TAG_NAME, "h2")
            name = name_element.text.strip()
            
            # Extraction du lien
            link_element = item.find_element(By.TAG_NAME, "a")
            relative_url = link_element.get_attribute("href")
            product_link = relative_url if relative_url.startswith("http") else BASE + relative_url

            print(f"üì¶ [Page {page_num}] [{index+1}/{len(product_items)}] Traitement de {name}...")

            # Gestion d'erreurs plus robuste
            max_retries = 3
            retry_count = 0
            
            while retry_count < max_retries:
                try:
                    # Acc√©der √† la page produit dans un nouvel onglet
                    driver.execute_script("window.open('');")
                    driver.switch_to.window(driver.window_handles[1])
                    
                    # Utiliser la fonction d'extraction am√©lior√©e
                    specs_dict, datasheet_link, image_url = extract_product_specs(driver, wait, product_link)
                    
                    # Si pas d'image trouv√©e, essayer l'image de la liste
                    if not image_url:
                        try:
                            driver.switch_to.window(driver.window_handles[0])
                            image_url = item.find_element(By.TAG_NAME, "img").get_attribute("src")
                            driver.switch_to.window(driver.window_handles[1])
                        except:
                            image_url = ""
                    
                    # ‚úÖ Ajout √† la liste selon le sch√©ma du cahier des charges
                    product_data = {
                        "brand": "Asus",
                        "link": product_link,
                        "name": name,
                        "tech_specs": specs_dict,
                        "scraped_at": datetime.now().isoformat(),
                        "datasheet_link": datasheet_link,
                        "image_url": image_url
                    }
                    
                    page_products.append(product_data)
                    print(f"‚úÖ [Page {page_num}] [{index+1}/{len(product_items)}] {name} - {len(specs_dict)} sp√©cifications extraites")
                    break  # Succ√®s, sortir de la boucle de retry
                    
                except Exception as e:
                    retry_count += 1
                    print(f"‚ö†Ô∏è Tentative {retry_count}/{max_retries} √©chou√©e pour {name}: {e}")
                    
                    if retry_count < max_retries:
                        # Fermer tous les onglets suppl√©mentaires et attendre
                        while len(driver.window_handles) > 1:
                            driver.switch_to.window(driver.window_handles[-1])
                            driver.close()
                        driver.switch_to.window(driver.window_handles[0])
                        
                        print(f"üîÑ Attente de {retry_count * 5} secondes avant retry...")
                        time.sleep(retry_count * 5)  # Attente progressive
                    else:
                        # Dernier √©chec, ajouter le produit avec infos minimales
                        print(f"‚ùå √âchec d√©finitif pour {name}, ajout avec infos de base")
                        page_products.append({
                            "brand": "Asus",
                            "link": product_link,
                            "name": name,
                            "tech_specs": {},
                            "scraped_at": datetime.now().isoformat(),
                            "datasheet_link": None,
                            "image_url": ""
                        })

            # Nettoyer : fermer l'onglet et revenir √† la liste
            try:
                while len(driver.window_handles) > 1:
                    driver.switch_to.window(driver.window_handles[-1])
                    driver.close()
                driver.switch_to.window(driver.window_handles[0])
            except:
                pass
            
            # Pause pour √©viter la surcharge (plus longue entre les produits)
            time.sleep(DELAY_BETWEEN_PRODUCTS)

        except Exception as e:
            print(f"‚ùå Erreur critique sur produit {index+1} de la page {page_num}: {e}")
            try:
                while len(driver.window_handles) > 1:
                    driver.switch_to.window(driver.window_handles[-1])
                    driver.close()
                driver.switch_to.window(driver.window_handles[0])
            except:
                pass
            continue
    
    return page_products

# ‚úÖ √âtape 1 : Extraire tous les produits avec pagination
print("üöÄ D√©marrage de l'extraction avec gestion de pagination...")
products_data = extract_all_products(driver, wait, URL)

driver.quit()

# ‚úÖ Export JSON
with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
    json.dump(products_data, f, ensure_ascii=False, indent=4)

print(f"\nüéØ Extraction termin√©e. {len(products_data)} produits enregistr√©s ‚Üí {OUTPUT_JSON}")

# ‚úÖ Sauvegarde en base de donn√©es MySQL
if ENABLE_DB:
    print("\nüíæ Sauvegarde en base de donn√©es...")
    try:
        save_to_database(OUTPUT_JSON, "serveurs", "Asus")
        print("‚úÖ Sauvegarde en base de donn√©es r√©ussie!")
    except Exception as e:
        print(f"‚ùå Erreur sauvegarde base de donn√©es: {e}")
        print("üí° Assurez-vous que MySQL est install√© et configur√©")
else:
    print("üíæ Sauvegarde BD d√©sactiv√©e (ENABLE_DB=false)")
